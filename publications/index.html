<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>publications | Yujia  Bao</title>
    <meta name="author" content="Yujia  Bao">
    <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar.">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%90%BE&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://yujiabao.github.io/publications/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Yujia¬†</span>Bao</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/bio/">üêæüêæüêæ</a>
              </li>
              <li class="nav-item active">
                <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/samoyed/">üêæüêæüêæ</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">publications</h1>
            <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p>
          </header>

          <article>
            <div class="publications">


  <h2 class="year">2023</h2>
  <ol class="bibliography"><li>
<div class="row" style="display:block">
  <div class="col-sm-2 abbr" style="margin: 0">
  
  </div>
  <div id="bao2023contextual" class="col-sm-8" style="margin: 0">
    
      <div class="title" style="fontsize: 120%">Contextual Vision Transformers for Robust Representation Learning</div>
      <div class="author" style="margin: 0">
        
          
          
          
          
          
            
              
                <strong>Yujia Bao</strong>,
              
            
          
        
          
          
          
          
          
            
              
                
                  and Theofanis Karaletsos
                
              
            
          
        
      </div>
      <div class="periodical">
      
        <em>Preprint</em>
      
      
        2023
      
      </div>
    
    <div class="links" style="margin: 0">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="https://arxiv.org/abs/2305.19402" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a>
    
    
    
    
    
    
    
    
    
    
    </div>
    <!--[> Hidden abstract block <]-->
    
    <div class="abstract hidden">
      <p>
        We present Contextual Vision Transformers (ContextViT), a method for
        producing robust feature representations for images exhibiting grouped
        structure such as covariates. ContextViT introduces an extra context
        token to encode group-specific information, allowing the model to
        explain away group-specific covariate structures while keeping core
        visual features shared across groups. Specifically, given an input
        image, Context-ViT maps images that share the same covariate into this
        context token appended to the input image tokens to capture the effects
        of conditioning the model on group membership. We furthermore introduce
        a context inference network to predict such tokens on the fly given a
        few samples from a group distribution, enabling ContextViT to generalize
        to new testing distributions at inference time. We illustrate the
        performance of ContextViT through a diverse range of applications. In
        supervised fine-tuning, we demonstrate that augmenting pre-trained ViTs
        with additional context conditioning leads to significant improvements
        in out-of-distribution generalization on iWildCam and FMoW. We also
        explored self-supervised representation learning with ContextViT. Our
        experiments on the Camelyon17 pathology imaging benchmark and the
        cpg-0000 microscopy imaging benchmark demonstrate that ContextViT excels
        in learning stable image featurizations amidst covariate shift,
        consistently outperforming its ViT counterpart.
    </p>
    </div>
    
    <!--[>[> Hidden bibtex block <]<]-->
    <!---->
  </div>
</div>
</li></ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography">
<li>
<div class="row" style="display:block">
  <div class="col-sm-2 abbr" style="margin: 0">
  
  </div>
  <div id="bao2022learning" class="col-sm-8" style="margin: 0">
    
      <div class="title" style="fontsize: 120%">Learning to Split for Automatic Bias Detection</div>
      <div class="author" style="margin: 0">
        
          
          
          
          
          
            
              
                <strong>Yujia Bao</strong>,
              
            
          
        
          
          
          
          
          
            
              
                
                  and Regina Barzilay
                
              
            
          
        
      </div>
      <div class="periodical">
      
        <em>Preprint</em>
      
      
        2022
      
      </div>
    
    <div class="links" style="margin: 0">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="https://arxiv.org/abs/2204.13749" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a>
    
    
    
    
    
    
    
      <a href="https://github.com/YujiaBao/ls" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a>
    
    
    
    
    </div>
    <!--[> Hidden abstract block <]-->
    
    <div class="abstract hidden">
      <p>Classifiers are biased when trained on biased datasets. As a remedy,
            we propose Learning to Split (ls), an algorithm for automatic bias
            detection. Given a dataset with input-label pairs, ls learns to
            split this dataset so that predictors trained on the training split
            generalize poorly to the testing split. This performance gap
            provides a proxy for measuring the degree of bias in the learned
            features and can therefore be used to reduce biases. Identifying
            non-generalizable splits is challenging as we don‚Äôt have any
            explicit annotations about how to split. In this work, we show that
            the prediction correctness of the testing example can be used as a
            source of weak supervision: generalization performance will drop if
            we move examples that are predicted correctly away from the testing
            split, leaving only those that are mispredicted. We evaluate our
            approach on Beer Review, Waterbirds, CelebA and MNLI. Empirical
            results show that ls is able to generate astonishingly challenging
            splits that correlate with human-identified biases. Moreover, we
            demonstrate that combining robust learning algorithms (such as group
            DRO) with splits identified by ls enables automatic de-biasing.
            Compared with previous state-of-the-arts, we substantially improves
            the worst-group performance (23.4% on average) when the source of
            biases is unknown during training and validation.
    </p>
    </div>
    
    <!--[>[> Hidden bibtex block <]<]-->
    <!---->
  </div>
</div>
</li>
<li>
<div class="row" style="display:block">
  <div class="col-sm-2 abbr" style="margin: 0">
  
  </div>
  <div id="bao2021learning" class="col-sm-8" style="margin: 0">
    
      <div class="title" style="fontsize: 120%">Learning Stable Classifiers by Transferring Unstable Features</div>
      <div class="author" style="margin: 0">
        
          
          
          
          
          
            
              
                <strong>Yujia Bao</strong>,
              
            
          
        
          
          
          
          
          
            
              
                
                  Shiyu Chang,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  and Regina Barzilay
                
              
            
          
        
      </div>
      <div class="periodical">
      
        <em>In International Conference on Machine Learning</em>
      
      
        2022
      
      </div>
    
    <div class="links" style="margin: 0">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="https://arxiv.org/abs/2106.07847" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a>
    
    
    
    
    
    
    
      <a href="https://github.com/YujiaBao/Tofu" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a>
    
    
    
    
    </div>
    <!--[> Hidden abstract block <]-->
    
    <div class="abstract hidden">
      <p>We study transfer learning in the presence of spurious
              correlations. We experimen- tally demonstrate that directly
              transferring the stable feature extractor learned on the source
              task may not eliminate these biases for the target task. However,
              we hypothesize that the unstable features in the source task and
              those in the target task are directly related. By explicitly
              informing the target classifier of the source task‚Äôs unstable
              features, we can regularize the biases in the target task.
              Specifically, we derive a representation that encodes the unstable
              features by contrasting different data environments in the source
              task. On the target task, we cluster data from this
              representation, and achieve robustness by minimizing the
              worst-case risk across all clusters. We evaluate our method on
              both text and image classifications. Empirical results demonstrate
              that our algorithm is able to maintain robustness on the target
              task, outperforming the best baseline by 22.9% in absolute
              accuracy across 12 trans- fer settings. Our code is available at
              https://github.com/YujiaBao/Tofu.</p>
    </div>
    
    <!--[>[> Hidden bibtex block <]<]-->
    <!---->
  </div>
</div>
</li>
</ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography">
<li>
<div class="row" style="display:block">
  <div class="col-sm-2 abbr" style="margin: 0">
  
  </div>
  <div id="bao2021predict" class="col-sm-8" style="margin: 0">
    
      <div class="title" style="fontsize: 120%">Predict then Interpolate: A Simple Algorithm to Learn Stable Classifiers</div>
      <div class="author" style="margin: 0">
        
          
          
          
          
          
            
              
                <strong>Yujia Bao</strong>,
              
            
          
        
          
          
          
          
          
            
              
                
                  Shiyu Chang,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  and Regina Barzilay
                
              
            
          
        
      </div>
      <div class="periodical">
      
        <em>In International Conference on Machine Learning</em>
      
      
        2021
      
      </div>
    
    <div class="links" style="margin: 0">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="https://arxiv.org/abs/2105.12628" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a>
    
    
    
    
    
    
    
      <a href="https://github.com/YujiaBao/Predict-then-Interpolate" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a>
    
    
    
    
    </div>
    <!--[> Hidden abstract block <]-->
    
    <div class="abstract hidden">
      <p>We propose Predict then Interpolate (PI), a simple algorithm for
              learning correlations that are stable across environments. The
              algorithm follows from the intuition that when using a classifier
              trained on one environment to make predictions on examples from
              another environment, its mistakes are informative as to which
              correlations are unstable. In this work, we prove that by
              interpolating the distributions of the correct predictions and the
              wrong predictions, we can uncover an oracle distribution where the
              unstable correlation vanishes. Since the oracle interpolation
              coefficients are not accessible, we use group distributionally
              robust optimization to minimize the worst-case risk across all
              such interpolations. We evaluate our method on both text
              classification and image classification. Empirical results
              demonstrate that our algorithm is able to learn robust classifiers
              (outperforms IRM by 23.85% on synthetic environments and 12.41% on
              natural environments). Our code and data are available at
              https://github.com/YujiaBao/Predict-then-Interpolate.</p>
    </div>
    
    <!--[>[> Hidden bibtex block <]<]-->
    <!---->
  </div>
</div>
</li>
<li>
<div class="row" style="display:block">
  <div class="col-sm-2 abbr" style="margin: 0">
  
  </div>
  <div id="mckinley2021disease" class="col-sm-8" style="margin: 0">
    
      <div class="title" style="fontsize: 120%">Disease spectrum of gastric cancer susceptibility genes</div>
      <div class="author" style="margin: 0">
        
          
          
          
          
          
            
              
                
                  Sophia K McKinley,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Preeti Singh,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Kanhua Yin,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Jin Wang,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Jingan Zhou,
                
              
            
          
        
          
          
          
          
          
            
              
                <strong>Yujia Bao</strong>,
              
            
          
        
          
          
          
          
          
            
              
                
                  Menghua Wu,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Kush Pathak,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  John T Mullen,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Danielle Braun,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  and Kevin S Hughes
                
              
            
          
        
      </div>
      <div class="periodical">
      
        <em>Medical Oncology</em>
      
      
        2021
      
      </div>
    
    <div class="links" style="margin: 0">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://link.springer.com/article/10.1007/s12032-021-01495-w" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">HTML</a>
    
    
    
    
    
    
    
    
    </div>
    <!--[> Hidden abstract block <]-->
    
    <div class="abstract hidden">
      <p>Pathogenic variants in germline cancer susceptibility genes can
            increase the risk of a large number of diseases. Our study aims to
            assess the disease spectrum of gastric cancer susceptibility genes
            and to develop a comprehensive resource of gene‚Äìdisease associations
            for clinicians. Twenty-seven potential germline gastric cancer
            susceptibility genes were identified from three review articles and
            from six commonly used genetic information resources. The diseases
            associated with each gene were evaluated via a semi-structured
            review of six genetic resources and an additional literature review
            using a natural language processing (NLP)-based procedure. Out of 27
            candidate genes, 13 were identified as gastric cancer susceptibility
            genes (APC, ATM, BMPR1A, CDH1, CHEK2, EPCAM, MLH1, MSH2, MSH6,
            MUTYH-Biallelic, PALB2, SMAD4, and STK11). A total of 145
            gene‚Äìdisease associations (with 45 unique diseases) were found to be
            associated with these 13 genes. Other gastrointestinal cancers were
            prominent among identified associations, with 11 of 13 gastric
            cancer susceptibility genes also associated with colorectal cancer,
            eight genes associated with pancreatic cancer, and seven genes
            associated with small intestine cancer. Gastric cancer
            susceptibility genes are frequently associated with other diseases
            as well as gastric cancer, with potential implications for how
            carriers of these genes are screened and managed. Unfortunately,
            commonly used genetic resources provide heterogeneous information
            with regard to these genes and their associated diseases,
            highlighting the importance of developing guides for clinicians that
            integrate data across available resources and the medical
            literature.</p>
    </div>
    
    <!--[>[> Hidden bibtex block <]<]-->
    <!---->
  </div>
</div>
</li>
<li>
<div class="row" style="display:block">
  <div class="col-sm-2 abbr" style="margin: 0">
  
  </div>
  <div id="zhou2021non" class="col-sm-8" style="margin: 0">
    
      <div class="title" style="fontsize: 120%">Non-medullary thyroid cancer susceptibility genes: evidence and disease spectrum</div>
      <div class="author" style="margin: 0">
        
          
          
          
          
          
            
              
                
                  Jingan Zhou,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Preeti Singh,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Kanhua Yin,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Jin Wang,
                
              
            
          
        
          
          
          
          
          
            
              
                <strong>Yujia Bao</strong>,
              
            
          
        
          
          
          
          
          
            
              
                
                  Menghua Wu,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Kush Pathak,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Sophia K McKinley,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Danielle Braun,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Carrie C Lubitz,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  and Kevin S Hughes
                
              
            
          
        
      </div>
      <div class="periodical">
      
        <em>Annals of Surgical Oncology</em>
      
      
        2021
      
      </div>
    
    <div class="links" style="margin: 0">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://link.springer.com/article/10.1245/s10434-021-09745-x" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">HTML</a>
    
    
    
    
    
    
    
    
    </div>
    <!--[> Hidden abstract block <]-->
    
    <div class="abstract hidden">
      <p>Background: The prevalence of non-medullary thyroid cancer (NMTC) is
            increasing worldwide. Although most NMTCs grow slowly, conventional
            therapies are less effective in advanced tumors. Approximately 5‚Äì15%
            of NMTCs have a significant germline genetic component. Awareness of
            the NMTC susceptibility genes may lead to earlier diagnosis and
            better cancer prevention.  Objective: The aim of this study was to
            provide the current panorama of susceptibility genes associated with
            NMTC and the spectrum of diseases associated with these genes.
            Methods: Twenty-five candidate genes were identified by searching
            for relevant studies in PubMed. Each candidate gene was carefully
            checked using six authoritative genetic resources: ClinGen, National
            Comprehensive Cancer Network guidelines, Online Mendelian
            Inheritance in Man, Genetics Home Reference, GeneCards, and
            Gene-NCBI, and a validated natural language processing (NLP)-based
            literature review protocol was used to further assess gene‚Äìdisease
            associations where there was ambiguity.  Results: Among 25 candidate
            genes, 10 (APC, DICER1, FOXE1, HABP2, NKX2-1, PRKAR1A, PTEN, SDHB,
            SDHD, and SRGAP1) were verified among the six genetic resources. Two
            additional genes, CHEK2 and SEC23B, were verified using the NLP
            protocol. Seventy-nine diseases were found to be associated with
            these 12 NMTC susceptibility genes. The following diseases were
            associated with more than one NMTC susceptibility gene: colorectal
            cancer, breast cancer, gastric cancer, kidney cancer,
            gastrointestinal stromal tumor, paraganglioma, pheochromocytoma, and
            benign skin conditions.  Conclusion: Twelve genes predisposing to
            NMTC and their associated disease spectra were identified and
            verified. Clinicians should be aware that patients with certain
            pathogenic variants may require more aggressive surveillance beyond
            their thyroid cancer risk.</p>
    </div>
    
    <!--[>[> Hidden bibtex block <]<]-->
    <!---->
  </div>
</div>
</li>
<li>
<div class="row" style="display:block">
  <div class="col-sm-2 abbr" style="margin: 0">
  
  </div>
  <div id="wang2021disease" class="col-sm-8" style="margin: 0">
    
      <div class="title" style="fontsize: 120%">Disease spectrum of breast cancer susceptibility genes</div>
      <div class="author" style="margin: 0">
        
          
          
          
          
          
            
              
                
                  Jin Wang,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Preeti Singh,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Kanhua Yin,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Jingan Zhou,
                
              
            
          
        
          
          
          
          
          
            
              
                <strong>Yujia Bao</strong>,
              
            
          
        
          
          
          
          
          
            
              
                
                  Menghua Wu,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Kush Pathak,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Sophia K McKinley,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Danielle Braun,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  and Kevin S Hughes
                
              
            
          
        
      </div>
      <div class="periodical">
      
        <em>Frontiers in Oncology</em>
      
      
        2021
      
      </div>
    
    <div class="links" style="margin: 0">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8093501/pdf/fonc-11-663419.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">HTML</a>
    
    
    
    
    
    
    
    
    </div>
    <!--[> Hidden abstract block <]-->
    
    <div class="abstract hidden">
      <p>Background: Pathogenic variants in cancer susceptibility genes can
            increase the risk of a spectrum of diseases, which clinicians must
            manage for their patients. We evaluated the disease spectrum of
            breast cancer susceptibility genes (BCSGs) with the aim of
            developing a comprehensive resource of gene-disease associations for
            clinicians. Methods: Twelve genes (ATM, BARD1, BRCA1, BRCA2, CDH1,
            CHEK2, NF1, PALB2, PTEN, RECQL, STK11, and TP53), all of which have
            been conclusively established as BCSGs by the Clinical Genome
            Resource (ClinGen) and/or the NCCN guidelines, were investigated.
            The potential gene-disease associations for these 12 genes were
            verified and evaluated based on six genetic resources (ClinGen,
            NCCN, OMIM, Genetics Home Reference, GeneCards, and Gene-NCBI) and
            an additional literature review using a semiautomated natural
            language processing (NLP) abstract classification procedure.
            Results: Forty-two diseases were found to be associated with one or
            more of the 12 BCSGs for a total of 86 gene-disease associations, of
            which 90% (78/86) were verified by ClinGen and/or NCCN. Four
            gene-disease associations could not be verified by either ClinGen or
            NCCN but were verified by at least three of the other four genetic
            resources. Four gene-disease associations were verified by the NLP
            procedure alone.  Conclusion: This study is unique in that it
            systematically investigates the reported disease spectrum of BCSGs
            by surveying multiple genetic resources and the literature with the
            aim of developing a single consolidated, comprehensive resource for
            clinicians. This innovative approach provides a general guide for
            evaluating gene-disease associations for BCSGs, potentially
            improving the clinical management of at-risk individuals.</p>
    </div>
    
    <!--[>[> Hidden bibtex block <]<]-->
    <!---->
  </div>
</div>
</li>
</ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography">
<li>
<div class="row" style="display:block">
  <div class="col-sm-2 abbr" style="margin: 0">
  
  </div>
  <div id="bao2020fewshot" class="col-sm-8" style="margin: 0">
    
      <div class="title" style="fontsize: 120%">Few-shot Text Classification with Distributional Signatures</div>
      <div class="author" style="margin: 0">
        
          
          
          
          
          
            
              
                <strong>Yujia Bao*</strong>,
              
            
          
        
          
          
          
          
          
            
              
                
                  Menghua Wu*,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Shiyu Chang,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  and Regina Barzilay
                
              
            
          
        
      </div>
      <div class="periodical">
      
        <em>In International Conference on Learning Representations</em>
      
      
        2020
      
      </div>
    
    <div class="links" style="margin: 0">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="https://arxiv.org/abs/1908.06039" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a>
    
    
    
      <a href="https://openreview.net/forum?id=H1emfT4twB" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">HTML</a>
    
    
    
    
    
      <a href="https://github.com/YujiaBao/Distributional-Signatures" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a>
    
    
    
    
    </div>
    <!--[> Hidden abstract block <]-->
    
    <div class="abstract hidden">
      <p>In this paper, we explore meta-learning for few-shot text classification. Meta-learning has shown strong performance in computer vision, where low-level patterns are transferable across learning tasks. However, directly applying this approach to text is challenging‚Äìwords highly informative for one task may have little significance for another. Thus, rather than learning solely from words, our model also leverages their distributional signatures, which encode pertinent word occurrence patterns. Our model is trained within a meta-learning framework to map these signatures into attention scores, which are then used to weight the lexical representations of words. We demonstrate that our model consistently outperforms prototypical networks in both few-shot text classification and relation classification by a significant margin across six benchmark datasets (19.96% on average in 1-shot classification).</p>
    </div>
    
    <!--[>[> Hidden bibtex block <]<]-->
    <!---->
  </div>
</div>
</li>
<li>
<div class="row" style="display:block">
  <div class="col-sm-2 abbr" style="margin: 0">
  
  </div>
  <div id="hughesnatural" class="col-sm-8" style="margin: 0">
    
      <div class="title" style="fontsize: 120%">Natural language processing to facilitate breast cancer research and management</div>
      <div class="author" style="margin: 0">
        
          
          
          
          
          
            
              
                
                  Kevin S. Hughes,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Jingan Zhou,
                
              
            
          
        
          
          
          
          
          
            
              
                <strong>Yujia Bao</strong>,
              
            
          
        
          
          
          
          
          
            
              
                
                  Preeti Singh,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Jin Wang,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  and Kanhua Yin
                
              
            
          
        
      </div>
      <div class="periodical">
      
        <em>The Breast Journal</em>
      
      
        2020
      
      </div>
    
    <div class="links" style="margin: 0">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/tbj.13718" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">HTML</a>
    
    
    
    
    
    
    
    
    </div>
    <!--[> Hidden abstract block <]-->
    
    <div class="abstract hidden">
      <p>The medical literature has been growing exponentially, and its size
            has become a barrier for physicians to locate and extract clinically
            useful information. As a promising solution, natural language
            processing (NLP), especially machine learning (ML)‚Äêbased NLP is a
            technology that potentially provides a promising solution. ML‚Äêbased
            NLP is based on training a computational algorithm with a large
            number of annotated examples to allow the computer to ‚Äúlearn‚Äù and
            ‚Äúpredict‚Äù the meaning of human language. Although NLP has been
            widely applied in industry and business, most physicians still are
            not aware of the huge potential of this technology in medicine, and
            the implementation of NLP in breast cancer research and management
            is fairly limited. With a real‚Äêworld successful project of
            identifying penetrance papers for breast and other cancer
            susceptibility genes, this review illustrates how to train and
            evaluate an NLP‚Äêbased medical abstract classifier, incorporate it
            into a semiautomatic meta‚Äêanalysis procedure, and validate the
            effectiveness of this procedure. Other implementations of NLP
            technology in breast cancer research, such as parsing pathology
            reports and mining electronic healthcare records, are also
            discussed. We hope this review will help breast cancer physicians
            and researchers to recognize, understand, and apply this technology
            to meet their own clinical or research needs.</p>
    </div>
    
    <!--[>[> Hidden bibtex block <]<]-->
    <!---->
  </div>
</div>
</li>
</ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography">
<li>
<div class="row" style="display:block">
  <div class="col-sm-2 abbr" style="margin: 0">
  
  </div>
  <div id="doi:10.1200/CCI.19.00043" class="col-sm-8" style="margin: 0">
    
      <div class="title" style="fontsize: 120%">Validation of a Semiautomated Natural Language Processing‚ÄìBased Procedure for Meta-Analysis of Cancer Susceptibility Gene Penetrance</div>
      <div class="author" style="margin: 0">
        
          
          
          
          
          
            
              
                
                  Zhengyi Deng*,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Kanhua Yin*,
                
              
            
          
        
          
          
          
          
          
            
              
                <strong>Yujia Bao</strong>,
              
            
          
        
          
          
          
          
          
            
              
                
                  Victor Diego Armengol,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Cathy Wang,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Ankur Tiwari,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Regina Barzilay,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Giovanni Parmigiani,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Danielle Braun,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  and Kevin S. Hughes
                
              
            
          
        
      </div>
      <div class="periodical">
      
        <em>JCO Clinical Cancer Informatics</em>
      
      
        2019
      
      </div>
    
    <div class="links" style="margin: 0">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://ascopubs.org/doi/abs/10.1200/CCI.19.00043" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">HTML</a>
    
    
    
    
    
      <a href="https://github.com/YujiaBao/PubmedClassifier" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a>
    
    
    
    
    </div>
    <!--[> Hidden abstract block <]-->
    
    <div class="abstract hidden">
      <p>PURPOSE: Quantifying the risk of cancer associated with pathogenic mutations in germline cancer susceptibility genes‚Äîthat is, penetrance‚Äîenables the personalization of preventive management strategies. Conducting a meta-analysis is the best way to obtain robust risk estimates. We have previously developed a natural language processing (NLP) ‚Äìbased abstract classifier which classifies abstracts as relevant to penetrance, prevalence of mutations, both, or neither. In this work, we evaluate the performance of this NLP-based procedure. MATERIALS AND METHODS: We compared the semiautomated NLP-based procedure, which involves automated abstract classification and text mining, followed by human review of identified studies, with the traditional procedure that requires human review of all studies. Ten high-quality gene‚Äìcancer penetrance meta-analyses spanning 16 gene‚Äìcancer associations were used as the gold standard by which to evaluate the performance of our procedure. For each meta-analysis, we evaluated the number of abstracts that required human review (workload) and the ability to identify the studies that were included by the authors in their quantitative analysis (coverage). RESULTS: Compared with the traditional procedure, the semiautomated NLP-based procedure led to a lower workload across all 10 meta-analyses, with an overall 84% reduction (2,774 abstracts v 16,941 abstracts) in the amount of human review required. Overall coverage was 93%‚Äîwe are able to identify 132 of 142 studies‚Äîbefore reviewing references of identified studies. Reasons for the 10 missed studies included blank and poorly written abstracts. After reviewing references, nine of the previously missed studies were identified and coverage improved to 99% (141 of 142 studies). CONCLUSION: We demonstrated that an NLP-based procedure can significantly reduce the review workload without compromising the ability to identify relevant studies. NLP algorithms have promising potential for reducing human efforts in the literature review process. </p>
    </div>
    
    <!--[>[> Hidden bibtex block <]<]-->
    <!---->
  </div>
</div>
</li>
<li>
<div class="row" style="display:block">
  <div class="col-sm-2 abbr" style="margin: 0">
  
  </div>
  <div id="bao2019using" class="col-sm-8" style="margin: 0">
    
      <div class="title" style="fontsize: 120%">Using Machine Learning and Natural Language Processing to Review and Classify the Medical Literature on Cancer Susceptibility Genes</div>
      <div class="author" style="margin: 0">
        
          
          
          
          
          
            
              
                <strong>Yujia Bao*</strong>,
              
            
          
        
          
          
          
          
          
            
              
                
                  Zhengyi Deng*,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Yan Wang,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Heeyoon Kim,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Victor Diego Armengol,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Francisco Acevedo,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Nofal Ouardaoui,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Cathy Wang,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Giovanni Parmigiani,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Regina Barzilay,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Danielle Braun,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  and Kevin S Hughes
                
              
            
          
        
      </div>
      <div class="periodical">
      
        <em>JCO Clinical Cancer Informatics</em>
      
      
        2019
      
      </div>
    
    <div class="links" style="margin: 0">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="https://arxiv.org/abs/1904.12617" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a>
    
    
    
      <a href="https://ascopubs.org/doi/pdf/10.1200/CCI.19.00042" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">HTML</a>
    
    
    
    
    
      <a href="https://github.com/YujiaBao/PubmedClassifier" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a>
    
    
    
    
    </div>
    <!--[> Hidden abstract block <]-->
    
    <div class="abstract hidden">
      <p>PURPOSE: The medical literature relevant to germline genetics is growing exponentially. Clinicians need tools monitoring and prioritizing the literature to understand the clinical implications of the pathogenic genetic variants. We developed and evaluated two machine learning models to classify abstracts as relevant to the penetrance (risk of cancer for germline mutation carriers) or prevalence of germline genetic mutations. METHODS: We conducted literature searches in PubMed and retrieved paper titles and abstracts to create an annotated dataset for training and evaluating the two machine learning classification models. Our first model is a support vector machine (SVM) which learns a linear decision rule based on the bag-of-ngrams representation of each title and abstract. Our second model is a convolutional neural network (CNN) which learns a complex nonlinear decision rule based on the raw title and abstract. We evaluated the performance of the two models on the classification of papers as relevant to penetrance or prevalence. RESULTS: For penetrance classification, we annotated 3740 paper titles and abstracts and evaluated the two models using 10-fold cross-validation. The SVM model achieves 88.93% accuracy (percentage of papers that were correctly classified) while the CNN model achieves 88.53 % accuracy. For prevalence classification, we annotated 3753 paper titles and abstracts. The SVM model achieves 88.92% accuracy while the CNN model achieves 88.52 % accuracy. CONCLUSION: Our models achieve high accuracy in classifying abstracts as relevant to penetrance or prevalence. By facilitating literature review, this tool could help clinicians and researchers keep abreast of the burgeoning knowledge of gene-cancer associations and keep the knowledge bases for clinical decision support tools up to date.</p>
    </div>
    
    <!--[>[> Hidden bibtex block <]<]-->
    <!---->
  </div>
</div>
</li>
<li>
<div class="row" style="display:block">
  <div class="col-sm-2 abbr" style="margin: 0">
  
  </div>
  <div id="baselineregularization" class="col-sm-8" style="margin: 0">
    
      <div class="title" style="fontsize: 120%">A Machine-Learning Based Drug Repurposing Approach Using Baseline Regularization</div>
      <div class="author" style="margin: 0">
        
          
          
          
          
          
            
              
                
                  Zhaobin Kuang,
                
              
            
          
        
          
          
          
          
          
            
              
                <strong>Yujia Bao</strong>,
              
            
          
        
          
          
          
          
          
            
              
                
                  James Thomson,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Michael Caldwell,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Peggy Peissig,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Ron Stewart,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Rebecca Willett,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  and David Page
                
              
            
          
        
      </div>
      <div class="periodical">
      
        <em>Invited book chapter, In Silico Methods for Drug Repurposing: Methods and Protocols,</em> Springer
      
      
        2019
      
      </div>
    
    <div class="links" style="margin: 0">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="/assets/pdf/baselineregularization.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>
    <!--[> Hidden abstract block <]-->
    
    <div class="abstract hidden">
      <p>We present the baseline regularization model for computational drug repurposing using electronic health records (EHRs). In EHRs, drug prescriptions of various drugs are recorded throughout time for various patients. In the same time, numeric physical measurements (e.g. fasting blood sugar level) are also recorded. Baseline regularization uses statistical relationships between the occurrences of prescriptions of some particular drugs and the increase or the decrease in the values of some particular numeric physical measurements to identify potential repurposing opportunities.</p>
    </div>
    
    <!--[>[> Hidden bibtex block <]<]-->
    <!---->
  </div>
</div>
</li>
</ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography"><li>
<div class="row" style="display:block">
  <div class="col-sm-2 abbr" style="margin: 0">
  
  </div>
  <div id="r2a" class="col-sm-8" style="margin: 0">
    
      <div class="title" style="fontsize: 120%">Deriving Machine Attention from Human Rationales</div>
      <div class="author" style="margin: 0">
        
          
          
          
          
          
            
              
                <strong>Yujia Bao</strong>,
              
            
          
        
          
          
          
          
          
            
              
                
                  Shiyu Chang,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Mo Yu,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  and Regina Barzilay
                
              
            
          
        
      </div>
      <div class="periodical">
      
        <em>In Empirical Methods in Natural Language Processing</em>
      
      
        2018
      
      </div>
    
    <div class="links" style="margin: 0">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="https://arxiv.org/abs/1808.09367" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a>
    
    
    
    
    
    
    
      <a href="https://github.com/YujiaBao/R2A" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a>
    
    
    
      
      <a href="/assets/pdf/r2a_slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>
    <!--[> Hidden abstract block <]-->
    
    <div class="abstract hidden">
      <p>Attention-based models are successful when trained on large amounts of data. In this paper, we demonstrate that even in the low-resource scenario, attention can be learned effectively. To this end, we start with discrete human-annotated rationales and map them into continuous attention. Our central hypothesis is that this mapping is general across domains, and thus can be transferred from resource-rich domains to low-resource ones. Our model jointly learns a domain-invariant representation and induces the desired mapping between rationales and attention. Our empirical results validate this hypothesis and show that our approach delivers significant gains over state-of-the-art baselines, yielding over 15% average error reduction on benchmark datasets.</p>
    </div>
    
    <!--[>[> Hidden bibtex block <]<]-->
    <!---->
  </div>
</div>
</li></ol>

  <h2 class="year">2017</h2>
  <ol class="bibliography"><li>
<div class="row" style="display:block">
  <div class="col-sm-2 abbr" style="margin: 0">
  
  </div>
  <div id="hawkes" class="col-sm-8" style="margin: 0">
    
      <div class="title" style="fontsize: 120%">Hawkes Process Modeling of Adverse Drug Reactions with Longitudinal Observational Data</div>
      <div class="author" style="margin: 0">
        
          
          
          
          
          
            
              
                <strong>Yujia Bao</strong>,
              
            
          
        
          
          
          
          
          
            
              
                
                  Zhaobin Kuang,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  Peggy Peissig,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  David Page,
                
              
            
          
        
          
          
          
          
          
            
              
                
                  and Rebecca Willett
                
              
            
          
        
      </div>
      <div class="periodical">
      
        <em>In Machine Learning for Healthcare Conference</em>
      
      
        2017
      
      </div>
    
    <div class="links" style="margin: 0">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="/assets/pdf/hawkes_pdf.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/YujiaBao/Hawkes-ADR" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a>
    
    
      
      <a href="/assets/pdf/hawkes_poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
      
      <a href="/assets/pdf/hawkes_slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>
    <!--[> Hidden abstract block <]-->
    
    <div class="abstract hidden">
      <p>Adverse drug reaction (ADR) discovery is the task of identifying unexpected and negative events caused by pharmaceutical products. This paper describes a log-linear Hawkes process model for ADR discovery from longitudinal observational data such as electronic health records (EHRs). The proposed method leverages the irregular time-stamped events in EHRs to represent the time-varying effect of various drugs on the occurrence rate of adverse events. Experimental results on a large-scale cohort of real-world EHRs demonstrate that the proposed method outperforms a leading approach, multiple self-controlled case series (Simpson et al., 2013), in identifying benchmark ADRs defined by the Observational Medical Outcomes Partnership.</p>
    </div>
    
    <!--[>[> Hidden bibtex block <]<]-->
    <!---->
  </div>
</div>
</li></ol>

  <h2 class="year">2016</h2>
  <ol class="bibliography"><li>
<div class="row" style="display:block">
  <div class="col-sm-2 abbr" style="margin: 0">
  
  </div>
  <div id="rrqr" class="col-sm-8" style="margin: 0">
    
      <div class="title" style="fontsize: 120%">Rank Revealing Algorithms and their Applications</div>
      <div class="author" style="margin: 0">
        
          
          
          
          
          
            
              <strong>Yujia Bao</strong>
            
          
        
      </div>
      <div class="periodical">
      
        <em>Bachelor Thesis, Shanghai Jiao Tong University,</em>
      
      
        2016
      
      </div>
    
    <div class="links" style="margin: 0">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="/assets/pdf/rrqr_pdf.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
      
      <a href="/assets/pdf/rrqr_slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>
    <!--[> Hidden abstract block <]-->
    
    <div class="abstract hidden">
      <p>As the era of big data is coming, rank revealing QR (RRQR) factorization has more and more applications on rank deficient problems such as subset selection, least squares problem, total least squares problem. This thesis systematically studied the RRQR algorithms. The main contributions are summarized as following:
1. This thesis presents a systematic review of three kinds of widely-used and high- performance RRQR algorithms. I extend some existing theorems and indepen- dently complete some parts of the theoretical analysis.
2. Based on the existing methods, I propose a new greedy strong RRQR algorithm for computing a strong RRQR factorization. The new algorithm greatly improves the time efficiency of the origin algorithm.
3. I design a series of numerical experiments to show the computation characteristics of different kinds of algorithms.
Theoretical analysis and numerical results show that both the origin strong RRQR al- gorithm and the new greedy strong RRQR algorithm can promise a strong RRQR fac- torization while the new algorithm is significantly faster than the origin algorithm. For rank deficient problem, RRQR factorization gives satisfactory computation accuracy while it is much more efficient than the traditional method, which involves computing the SVD.</p>
    </div>
    
    <!--[>[> Hidden bibtex block <]<]-->
    <!---->
  </div>
</div>
</li></ol>


</div>

          </article>

        </div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        ¬© Copyright 2023 Yujia  Bao. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.
Last updated: June 01, 2023.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
